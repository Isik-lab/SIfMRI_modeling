{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed353da",
   "metadata": {},
   "source": [
    "## Batched Feature Maps:\n",
    "\n",
    "For more flexible manipulation of data in various batch sizes, and for troubleshooting of feature extraction errors that may be inconsistent across batches (i.e. with next-token-predicting LLMs.) Below are two examples of the use of batched feature maps:\n",
    "- The canonical AlexNet example.\n",
    "- A more complicated GPT example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b943db1",
   "metadata": {},
   "source": [
    "First, some setup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6b193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path += ['..']\n",
    "# add deepjuice to your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ccb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08fbedcb-03bf-42a2-bf2b-79fc7c2bcf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepjuice import * # the juice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ae5c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DeepJuice Benchmarks (JuicyFruits)\n",
      "Loading DeepJuice NSDBenchmark: \n",
      "  Image Set: shared1000\n",
      "  Voxel Set: ['EVC', 'OTC']\n"
     ]
    }
   ],
   "source": [
    "from juicyfruits import NSDBenchmark\n",
    "benchmark = NSDBenchmark() #load brain data benchmark\n",
    "\n",
    "model_uid = 'torchvision_alexnet_imagenet1k_v1'\n",
    "model, preprocess = get_deepjuice_model(model_uid)\n",
    "\n",
    "# here, we'll subset our images to simulate\n",
    "# a slightly uneven split across batches:\n",
    "image_subset = benchmark.image_paths[:160]\n",
    "\n",
    "dataloader = get_data_loader(image_subset, preprocess, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62fdfa0",
   "metadata": {},
   "source": [
    "**The Modified Extraction Procedure**\n",
    "\n",
    "...works almost exactly the same as before, except there's a new key argument:\n",
    "\n",
    "**batch_strategy**: 3 main variants\n",
    "- *join* constructs empty tensors in full dimension, and fills them iteratively with each batch.\n",
    "- *list* quite literally adds each batch of features to a list, and returns that list.\n",
    "- *stack* wraps this list in a class that allows for easier manipulation of the underlying nested list.\n",
    "\n",
    "\n",
    "*join* is the canonical version you're used to and is most efficient, but also can lead to a lot of degeneracies it turns out if batch_sizes are irregular, transfer between tensor devices is slow, or many other things...*list* is as it's written on the tin; each new batch of feature is dropped into a list, and that list is returned at the end of the function. *stack* is the version that directly uses the BatchedFeatureMaps class, but keep in mind that you can simply use the output of the *list* version after it's been built to initialize this class.\n",
    "\n",
    "Let's have a look at the list version first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d81d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sample feature_maps with torchinfo (CUDA:0 to CPU)\n",
      "Keeping 18 / 24 total maps (6 duplicates removed).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59510a52ce44f2fbfc305ad70f4ae63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Feature Extraction (DataLoader):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MPS is a mac GPU device that I'm using as stopgap:\n",
    "devices = {'device': 'cuda:0', 'output_device': 'cpu'}\n",
    "\n",
    "# notice that I'm invoking the get_feature_maps function directly\n",
    "# this is the function internally called by the FeatureExtractor:\n",
    "feature_map_list = get_feature_maps(model, dataloader, **devices,\n",
    "                                   batch_strategy='list') # <- the new argument!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e495b",
   "metadata": {},
   "source": [
    "So what does feature_map_list look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8326f2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureMaps Handle\n",
       "  18 maps; 64 inputs; 262.60 MB \n",
       "  0 maps on GPU (0 duplicates),\n",
       " FeatureMaps Handle\n",
       "  18 maps; 64 inputs; 262.60 MB \n",
       "  0 maps on GPU (0 duplicates),\n",
       " FeatureMaps Handle\n",
       "  18 maps; 32 inputs; 131.30 MB \n",
       "  0 maps on GPU (0 duplicates)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map_list # notice the last of these feature_maps has only 32 inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de7171",
   "metadata": {},
   "source": [
    "...in this example, feature_map_list is not a list of dictionaries as you might expect, but a list of what I call \"FeatureMap\" handles. These basically behave almost EXACTLY like a dictionary, but don't pollute ipython with numerical printouts. they also give us access to a bunch of quick stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce622cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear-2-15 [64, 4096]\n",
      "Linear-2-18 [64, 4096]\n",
      "Linear-2-20 [64, 1000]\n",
      "\n",
      " Number of inputs: 64\n"
     ]
    }
   ],
   "source": [
    "batch_one_maps = feature_map_list[0]\n",
    "\n",
    "# note how these behave exactly like dictionaries:\n",
    "for uid, feature_map in batch_one_maps.items():\n",
    "    if 'Linear' in uid: # print linear layers:\n",
    "        print(uid, [x for x in feature_map.shape])\n",
    "    \n",
    "# but also give you cool, quick stats:\n",
    "print('\\n Number of inputs:', batch_one_maps.get_input_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac2a06",
   "metadata": {},
   "source": [
    "With this in mind now, you can think of BatchedFeatureMaps as simply a wrapper around the FeatureMap wrappers (don't worry -- this is the most recursive this will get, I think...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "807016fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepjuice.extraction import BatchedFeatureMaps\n",
    "\n",
    "batched_maps = BatchedFeatureMaps(feature_map_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31bd8a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch Tensor Maps Handler\n",
       "  Total Batch Count: 3\n",
       "  Total Input Count: 160\n",
       "  # of Unique Feature Maps: 18\n",
       "  No irregularities found."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_maps # the initial report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb310c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this returns None in this case:\n",
    "batched_maps.get_irregular_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e3c6d",
   "metadata": {},
   "source": [
    "Note, this modification to the \"batch_strategy\" procedure can be wrapped directly into a FeatureExtractor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e01618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sample feature_maps with torchinfo (CUDA:0 to CPU)\n",
      "FeatureExtractor Handle for AlexNet\n",
      "  24 feature maps (+6 duplicates); 160 inputs\n",
      "  Memory required for full extraction: 677.15 MB\n",
      "  Memory usage limiting device set to: cpu\n",
      "  Memory usage limit currently set to: 371.294 GB\n",
      "  1 batch(es) required for current memory limit \n",
      "   Batch-001: 24 feature maps; 677.15 MB\n"
     ]
    }
   ],
   "source": [
    "devices = {'device': 'cuda:0', 'output_device': 'cpu'}\n",
    "\n",
    "extractor = FeatureExtractor(model, dataloader, **devices,\n",
    "                             batch_strategy='stack',\n",
    "                             max_memory_limit='16GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e68483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86c4cdfad0d47a6b106c70ef72b9920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irregularly shaped feature_maps excluded by default.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba56b2fb8c754772ace005e2ad52fab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining Batched Feature Maps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear-2-15 [160, 4096]\n",
      "Linear-2-18 [160, 4096]\n",
      "Linear-2-20 [160, 1000]\n"
     ]
    }
   ],
   "source": [
    "for batched_feature_maps in tqdm(extractor, 'Global Progress'):\n",
    "    feature_maps = batched_feature_maps.join_batches()\n",
    "    for uid, feature_map in feature_maps.items():\n",
    "        if 'Linear' in uid: # print linear layers:\n",
    "            print(uid, [x for x in feature_map.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b578732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069f06fee6cd4a3ca5212dfec10db651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irregularly shaped feature_maps excluded by default.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eddc5f32e64e78ab42fb18bb848fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining Batched Feature Maps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d-2-1 [160, 193600]\n",
      "Conv2d-2-4 [160, 139968]\n",
      "Conv2d-2-7 [160, 64896]\n",
      "Conv2d-2-9 [160, 43264]\n",
      "Conv2d-2-11 [160, 43264]\n"
     ]
    }
   ],
   "source": [
    "# this will also work if we add a flattening modification\n",
    "\n",
    "extractor.modify_settings(flatten=True)\n",
    "\n",
    "for batched_feature_maps in tqdm(extractor, 'Global Progress'):\n",
    "    feature_maps = batched_feature_maps.join_batches()\n",
    "    for uid, feature_map in feature_maps.items():\n",
    "        if 'Conv2d' in uid: # print linear layers:\n",
    "            print(uid, [x for x in feature_map.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e33fe-377f-419a-a727-4ad2d32f8fe0",
   "metadata": {},
   "source": [
    "## Huggingface GPT2 Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee27663-4222-440d-924b-30d6736ca126",
   "metadata": {},
   "source": [
    "Now, a more complicated example, using real text (captions) data in a generative LLM (Huggingface's GPT2).\n",
    "\n",
    "First, we loads the captions data and our target model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8729078-7c8a-49e0-99e0-2db6fb114829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_assist import parse_caption_data\n",
    "\n",
    "caption_path = 'example_data/social_captions'\n",
    "caption_data = parse_caption_data(f'{caption_path}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97457dd7-b3f6-4011-80e7-70c444d562f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_uid = 'gpt2' # huggingface implemented\n",
    "\n",
    "# standard loader without additional configs:\n",
    "model = AutoModel.from_pretrained(model_uid)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_uid)\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.resize_token_embeddings(len(tokenizer));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f63a7f-4163-418b-84dc-b9daaf6a4a59",
   "metadata": {},
   "source": [
    "The batched_feature_maps functionality can really come in handy in two particular scenarios.\n",
    "\n",
    "The 1st scenario is where certain feature_map shapes may change across batches. <br>The 2nd scenario is where we might want different numbers of batch sizes.\n",
    "\n",
    "This example will cover both of these scenarios. Here, we're working with a generative LLM, whose last layer (by default) produces a whole bunch of tensors (including *past_key_values*) that it sandwiches into a tuple.\n",
    "\n",
    "To get variable batch sizes into our dataloader, we use a Torch class on the backend called BatchSampler. On the frontend, all we need to do is provide a dataframe, and a grouping variable that will assist our BatchSampler in choosing batches that get all inputs within a certain group into the same batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b58d3b9-90bc-458d-8218-8869df26173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is our new dataloader functionality; notice data_key and group_keys:\n",
    "dataloader = get_data_loader(caption_data, tokenizer, input_modality='text',\n",
    "                             batch_size=16, data_key='caption', group_keys='video_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16abd558-88fb-43e4-a38e-1ee9be4ad7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader with 101 batches.\n",
       "  Batch sizes range from: 6 to 16\n",
       "  with an average size of: ~13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader # by default, dataloader now comes packaged with additional info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcf98eab-03e9-4da3-847e-91deb42d5644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Young boys are playing on a pair of drum sets.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([20917,  6510,   389,  ..., 50257, 50257, 50257]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note this loader can now yield samples!\n",
    "dataloader.get_sample(show_original=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558b896-ed79-4607-8229-f11a8506cec8",
   "metadata": {},
   "source": [
    "The data used to produce the variable batch sizes is directly available in the dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a048cc2c-f9ed-4dd5-82e3-2fc1f4656867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>caption_index</th>\n",
       "      <th>caption</th>\n",
       "      <th>group_index</th>\n",
       "      <th>batch_iter</th>\n",
       "      <th>batch_index</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-YwZOeyAQC8_15.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>A man playing on the wii which is making the b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-YwZOeyAQC8_15.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>A man in shorts sits in a chair next to a stan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-YwZOeyAQC8_15.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>A man with a baby on his lap playing Wii</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-YwZOeyAQC8_15.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>father &amp; child enjoying a show</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-YwZOeyAQC8_15.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>A man sits playing video games on his TV while...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>yt_R-8XFRghgHAwk_54.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>An adult helping a small baby to open a wrappe...</td>\n",
       "      <td>249</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>yt_R-8XFRghgHAwk_54.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>a a baby sitting on his fathers knee while his...</td>\n",
       "      <td>249</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>yt_R-8XFRghgHAwk_54.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>A man helping a baby unwrap a present.</td>\n",
       "      <td>249</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>yt_R-8XFRghgHAwk_54.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>A dad helping a baby to unwrap a present</td>\n",
       "      <td>249</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>yt_R-8XFRghgHAwk_54.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>A man is holding a baby in his lap and is help...</td>\n",
       "      <td>249</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1391 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   video_name  caption_index  \\\n",
       "0          -YwZOeyAQC8_15.mp4              1   \n",
       "2          -YwZOeyAQC8_15.mp4              2   \n",
       "4          -YwZOeyAQC8_15.mp4              3   \n",
       "6          -YwZOeyAQC8_15.mp4              4   \n",
       "8          -YwZOeyAQC8_15.mp4              5   \n",
       "...                       ...            ...   \n",
       "1382  yt_R-8XFRghgHAwk_54.mp4              1   \n",
       "1384  yt_R-8XFRghgHAwk_54.mp4              2   \n",
       "1386  yt_R-8XFRghgHAwk_54.mp4              3   \n",
       "1388  yt_R-8XFRghgHAwk_54.mp4              4   \n",
       "1390  yt_R-8XFRghgHAwk_54.mp4              5   \n",
       "\n",
       "                                                caption  group_index  \\\n",
       "0     A man playing on the wii which is making the b...            0   \n",
       "2     A man in shorts sits in a chair next to a stan...            0   \n",
       "4              A man with a baby on his lap playing Wii            0   \n",
       "6                        father & child enjoying a show            0   \n",
       "8     A man sits playing video games on his TV while...            0   \n",
       "...                                                 ...          ...   \n",
       "1382  An adult helping a small baby to open a wrappe...          249   \n",
       "1384  a a baby sitting on his fathers knee while his...          249   \n",
       "1386             A man helping a baby unwrap a present.          249   \n",
       "1388           A dad helping a baby to unwrap a present          249   \n",
       "1390  A man is holding a baby in his lap and is help...          249   \n",
       "\n",
       "      batch_iter  batch_index  batch_size  \n",
       "0              0            0          10  \n",
       "2              0            2          10  \n",
       "4              0            4          10  \n",
       "6              0            6          10  \n",
       "8              0            8          10  \n",
       "...          ...          ...         ...  \n",
       "1382         100            1          10  \n",
       "1384         100            3          10  \n",
       "1386         100            5          10  \n",
       "1388         100            7          10  \n",
       "1390         100            9          10  \n",
       "\n",
       "[1391 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.batch_data.sort_values(by=['group_index', 'caption_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b6c1e-a791-455e-bdef-3c4f8111b27e",
   "metadata": {},
   "source": [
    "(In this example, since GPT2 is REAL big, let's just look at the first 3 batches):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e8433d4-601f-4d20-9489-cd8ee7db9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_subset = (dataloader.batch_data.sort_values(by=['group_index', 'caption_index'])\n",
    "                  .query('batch_iter < 3'))[['video_name', 'caption_index', 'caption']]\n",
    "\n",
    "# define a new dataloader with only these captions:\n",
    "dataloader = get_data_loader(caption_subset, tokenizer, input_modality='text',\n",
    "                             batch_size=16, data_key='caption', group_keys='video_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b975d6-fb4e-4f5b-a3c8-357cbd205013",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_and_sweep() # clear the CUDA cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cd3ca97-ea81-4491-8ebe-3f449c38e49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sample feature_maps with torchinfo (CUDA:0 to CPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction Error Report\n",
      "(These Layers Skipped)\n",
      "  Embedding-1-2\n",
      "   --(add_features) IndexError: No dimension equal to input_size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureExtractor Handle for GPT2Model\n",
      "  185 feature maps (+61 duplicates); 33 inputs\n",
      "  Memory required for full extraction: 49.695 GB\n",
      "  Memory usage limiting device set to: cpu\n",
      "  Memory usage limit currently set to: 365.151 GB\n",
      "  1 batch(es) required for current memory limit \n",
      "   Batch-001: 185 feature maps; 49.695 GB\n"
     ]
    }
   ],
   "source": [
    "extractor = FeatureExtractor(model, dataloader, batch_strategy='stack', **devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d508b1ae-296f-45b6-a853-76f09bf40adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f879fe3f98401c9547805711891d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Tensor Maps Handler\n",
      "  Total Batch Count: 3\n",
      "  Total Input Count: 33\n",
      "  # of Unique Feature Maps: 185\n",
      "  # Irregular Shapes: 25\n"
     ]
    }
   ],
   "source": [
    "for batched_feature_maps in tqdm(extractor, 'Overall Progress'):\n",
    "    print(batched_feature_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5b7e4-e48b-44e3-b3bc-923ef3afb547",
   "metadata": {},
   "source": [
    "Notice here that when loading GPT2 without additional configurations or keyword arguments, that we can get some irregularly shaped feature_maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "310e9ee0-5841-452b-a3ec-b5f940013b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPT2Model-S2': [[2, 10, 12, 1024, 64],\n",
       "  [2, 11, 12, 1024, 64],\n",
       "  [2, 12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-1-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-2-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-2-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-6-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-3-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-10-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-4-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-14-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-5-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-18-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-6-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-22-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-7-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-26-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-8-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-30-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-9-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-34-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-10-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-38-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-11-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-42-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Block-2-12-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]],\n",
       " 'GPT2Attention-3-46-S2': [[10, 12, 1024, 64],\n",
       "  [11, 12, 1024, 64],\n",
       "  [12, 12, 1024, 64]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_feature_maps.get_irregular_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04f53d-80e2-46c0-8796-3cc11d5cfc90",
   "metadata": {},
   "source": [
    "The reason this is happening is due to a recent update in how Huggingface \"evaluates\" CLM-style LLM models by default. Unless otherwise configured, these models will store a cache of tensor values that facilitate next word prediction, but are confusingly shaped. \n",
    "\n",
    "See for example [this section](https://huggingface.co/transformers/v3.5.1/model_doc/gpt2.html#gpt2lmheadmodel) in the Huggingface documentation for more information on this caching procedure and its downstream dimensionality.\n",
    "\n",
    "For now, and for most intents and purposes, we actually don't want need or even want this cached information, and can safely exclude it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cabac514-9163-475a-875b-f603e7f0a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_uid = 'gpt2' # huggingface implemented\n",
    "\n",
    "#! note now this config we'll add:\n",
    "model_config = {'use_cache': False}\n",
    "\n",
    "model = AutoModel.from_pretrained(model_uid, **model_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_uid)\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.resize_token_embeddings(len(tokenizer));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd94cf7-5193-4f62-8a73-353b3d5e74b5",
   "metadata": {},
   "source": [
    "Now, when we run our same procedure, you'll notice we get no irregular shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbcc4ace-97b2-4ebe-bb58-e9e1369be1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_subset = (dataloader.batch_data.sort_values(by=['group_index', 'caption_index'])\n",
    "                  .query('batch_iter < 3'))[['video_name', 'caption_index', 'caption']]\n",
    "\n",
    "# define a new dataloader with only these captions:\n",
    "dataloader = get_data_loader(caption_subset, tokenizer, input_modality='text',\n",
    "                             batch_size=16, data_key='caption', group_keys='video_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2978fa80-42de-430c-a259-3075ad20b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sample feature_maps with torchinfo (CUDA:0 to CPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction Error Report\n",
      "(These Layers Skipped)\n",
      "  Embedding-1-2\n",
      "   --(add_features) IndexError: No dimension equal to input_size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureExtractor Handle for GPT2Model\n",
      "  160 feature maps (+49 duplicates); 33 inputs\n",
      "  Memory required for full extraction: 42.153 GB\n",
      "  Memory usage limiting device set to: cpu\n",
      "  Memory usage limit currently set to: 16.000 GB\n",
      "  3 batch(es) required for current memory limit \n",
      "   Batch-001: 59 feature maps; 14.792 GB \n",
      "   Batch-002: 57 feature maps; 15.856 GB \n",
      "   Batch-003: 44 feature maps; 11.505 GB\n"
     ]
    }
   ],
   "source": [
    "clean_and_sweep() # clear the CUDA cache\n",
    "\n",
    "extractor = FeatureExtractor(model, dataloader, **devices,\n",
    "                             memory_limit='16GB',\n",
    "                             batch_strategy='stack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de415c0e-61c4-45f3-b83f-93ac7dac16c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84b770212984f8fb7b3eed12205b996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irregularly shaped feature_maps excluded by default.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4caa1dd08d4e494285417bdf2ad2a2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining Batched Feature Maps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Attention-3-2 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-6 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-10 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-14 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-18 torch.Size([33, 1024, 768])\n",
      "Irregularly shaped feature_maps excluded by default.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058bd7c062c74f52964966a10ab22693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining Batched Feature Maps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Attention-3-22 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-26 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-30 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-34 torch.Size([33, 1024, 768])\n",
      "Irregularly shaped feature_maps excluded by default.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bfb7553d704c2796cdd9066da4cbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining Batched Feature Maps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Attention-3-38 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-42 torch.Size([33, 1024, 768])\n",
      "GPT2Attention-3-46 torch.Size([33, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "for batched_feature_maps in tqdm(extractor, 'Overall Progress'):\n",
    "    feature_maps = batched_feature_maps.join_batches()\n",
    "    for uid, feature_map in feature_maps.items():\n",
    "        if 'Attention' in uid:\n",
    "            print(uid, feature_map.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ecf52-3e6e-4407-8a85-8afaf04dadec",
   "metadata": {},
   "source": [
    "As a last step in this walkthrough, we'll show how we can combine batched_feature_maps with our variable batch sampler to save disk space by averaging feature_maps over the multiple samples of caption we have per image.\n",
    "\n",
    "We do this simply by constructing a function that leverages the batch data in our sampler to compute averages *per group*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9016b21a-b8ad-4062-a6d1-21ba3fc908ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store batch_data to directly access\n",
    "# the groups in our batching function:\n",
    "batch_data = dataloader.batch_data.copy()\n",
    "\n",
    "def grouped_average(tensor, batch_iter=None, **kwargs):\n",
    "    if batch_iter is None: return tensor # as is\n",
    "        \n",
    "    sub_data = batch_data.query('batch_iter==@batch_iter')\n",
    "\n",
    "    tensor_means = [] # fill with group tensor means\n",
    "    for group in sub_data.group_index.unique():\n",
    "        group_data = sub_data.query('group_index==@group')\n",
    "        group_idx = group_data.batch_index.to_list()\n",
    "\n",
    "        # convert index to tensor on device\n",
    "        group_idx = (torch.LongTensor(group_idx)\n",
    "                     .to(tensor.device))\n",
    "\n",
    "        tensor_mean = tensor[group_idx].mean(dim=0)\n",
    "        tensor_means += [tensor_mean.unsqueeze(0)]\n",
    "\n",
    "    return torch.concat(tensor_means, dim=0) # as is for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72a105-26cd-4da0-8978-5e8a87868e89",
   "metadata": {},
   "source": [
    "... then adding it to our extractor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c218fc26-fefb-4ba5-ac21-e8e9cf9f60a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sample feature_maps with torchinfo (CUDA:0 to CPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction Error Report\n",
      "(These Layers Skipped)\n",
      "  Embedding-1-2\n",
      "   --(add_features) IndexError: No dimension equal to input_size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureExtractor Handle for GPT2Model\n",
      "  160 feature maps (+49 duplicates); 33 inputs\n",
      "  Memory required for full extraction: 42.153 GB\n",
      "  Memory usage limiting device set to: cpu\n",
      "  Memory usage limit currently set to: 16.000 GB\n",
      "  3 batch(es) required for current memory limit \n",
      "   Batch-001: 59 feature maps; 14.792 GB \n",
      "   Batch-002: 57 feature maps; 15.856 GB \n",
      "   Batch-003: 44 feature maps; 11.505 GB\n"
     ]
    }
   ],
   "source": [
    "clean_and_sweep() # clear the CUDA cache\n",
    "\n",
    "extractor = FeatureExtractor(model, dataloader, **devices,\n",
    "                             # note the function here:\n",
    "                             tensor_fn=grouped_average,\n",
    "                             memory_limit='16GB',\n",
    "                             batch_strategy='stack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4c4d650-bf4a-4dda-bc03-66bfed93119b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e70e8d81bfd47fbaa6d0ae21db4ea11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irregularly shaped feature_maps excluded by default.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba621feed50f4699a4587b41532964d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining Batched Feature Maps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Attention-3-2 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-6 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-10 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-14 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-18 torch.Size([5, 1024, 768])\n",
      "Irregularly shaped feature_maps excluded by default.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1695bd0d90f488d8613f4d1d32a05c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining Batched Feature Maps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Attention-3-22 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-26 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-30 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-34 torch.Size([5, 1024, 768])\n",
      "Irregularly shaped feature_maps excluded by default.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7600daff4deb4d53aa6ec5349ca91d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining Batched Feature Maps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Attention-3-38 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-42 torch.Size([5, 1024, 768])\n",
      "GPT2Attention-3-46 torch.Size([5, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "for batched_feature_maps in tqdm(extractor, 'Overall Progress'):\n",
    "    feature_maps = batched_feature_maps.join_batches()\n",
    "    for uid, feature_map in feature_maps.items():\n",
    "        if 'Attention' in uid:\n",
    "            print(uid, feature_map.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0db268-8444-478f-b0d3-38e0848a975a",
   "metadata": {},
   "source": [
    "And there you have it; the use of batched_feature_maps and averaging to extract features from GPT2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8a984-f55a-4c69-b9c0-c985f786d740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Synthese",
   "language": "python",
   "name": "synthese"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01e154d8de2d47c4868d854a3cf9e781": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "030d3326eaa342c792a97b0b792cdaf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "040d6940cb4d4a55a59733bed8c015b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "058bd7c062c74f52964966a10ab22693": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0674b9f8bab7438d960661a9b4636b1c",
        "IPY_MODEL_fa1879106eae41c493c3a501d2f9e138",
        "IPY_MODEL_2c9691778d2742c49d566a5eace0960c"
       ],
       "layout": "IPY_MODEL_8a640a32504e47e2943c2f5acd6d4341"
      }
     },
     "0674b9f8bab7438d960661a9b4636b1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0c2d13c37ca94e3e9849610543192524",
       "style": "IPY_MODEL_42ab6708fe7c46b9951fabdf724f615d",
       "value": "Joining Batched Feature Maps: 100%"
      }
     },
     "069f06fee6cd4a3ca5212dfec10db651": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7dcc5538628e4467be225c705c1c594e",
        "IPY_MODEL_37e167a1ffee41d0b92ef844261715fd",
        "IPY_MODEL_2f6ee2dcbde24a5cb638813e1b2661d2"
       ],
       "layout": "IPY_MODEL_2b1030a5c07d49e8a42ec3f0a855dfb8"
      }
     },
     "0c2d13c37ca94e3e9849610543192524": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "13c9a4566fcc45499bad884654c2e09a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "170fad9d3d8c48d68d93d902cc4b31e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3b7a861dcb8147f8ba98aadf78fbc729",
       "max": 3,
       "style": "IPY_MODEL_7d91f76fe60e4de0924a7fd767484f4b",
       "value": 3
      }
     },
     "1a03db16015146cfafd36670f0cbcbf7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1b67d92e26f549199c816c82119af34a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1d0ae89144614e8ba431c8f3b411d843": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1de317b0b8084e22a1c1bd594ee734e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1f0eb997a63d41c18738c761985db8af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_7b06d52d098e47888ca00da88405443e",
       "max": 1,
       "style": "IPY_MODEL_040d6940cb4d4a55a59733bed8c015b2",
       "value": 1
      }
     },
     "2053625813304b0fb20ecd16b9344c55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_80278bf58cb449518089a73281d7552e",
       "style": "IPY_MODEL_f41738459f2945129c19d3f51ad2547e",
       "value": "Overall Progress: 100%"
      }
     },
     "210867d9f93e4cb5b4be0f1ab98eade9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "235d69ffff014c999f79525a7516f3c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "26b2e5eced6544509450d6bbc649dbf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_452a01dcd9d7414f86b3a1e9cb48caf4",
       "style": "IPY_MODEL_5dfc27425ed84c2dbe7ce84107e49219",
       "value": " 3/3 [00:16&lt;00:00,  3.69s/it]"
      }
     },
     "2859c9c4151a4d15840a975080aa4819": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "29fd666305c340ff92e3ecc54d92e7e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2a3e800acfcd42199140962eb3475c65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2b1030a5c07d49e8a42ec3f0a855dfb8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2bac393dd90f4656834cd50e2316d0a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f6a30bc60d554f0aae74aab64ef6bf25",
       "max": 3,
       "style": "IPY_MODEL_8ebbbe12136b4c559182346faa4c0f9f",
       "value": 3
      }
     },
     "2c9691778d2742c49d566a5eace0960c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_67443b92adbd4c1fb92507d9df324e02",
       "style": "IPY_MODEL_8aa84a197c2e43a3a61139b15e527075",
       "value": " 3/3 [00:00&lt;00:00,  3.50it/s]"
      }
     },
     "2f6ee2dcbde24a5cb638813e1b2661d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1d0ae89144614e8ba431c8f3b411d843",
       "style": "IPY_MODEL_ddbbbdb21cb04012825ffae89fbdbba1",
       "value": " 1/1 [00:02&lt;00:00,  2.11s/it]"
      }
     },
     "30e4b33f169e4dc5ace5e3965f21ee98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "32804186dad9440c88f802d2571b63f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "33a73e19318242c1b4158fb6de0c31ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "352f0ea477e34bd68a525fcf141f1086": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_910dab153cba484eb3e2524d01a397ce",
       "style": "IPY_MODEL_1a03db16015146cfafd36670f0cbcbf7",
       "value": "Joining Batched Feature Maps: 100%"
      }
     },
     "353edd792cca4bc59b24cc9090ce929b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_13c9a4566fcc45499bad884654c2e09a",
       "style": "IPY_MODEL_96602110095946d6a41f88a77eb46a27",
       "value": "Joining Batched Feature Maps: 100%"
      }
     },
     "37e167a1ffee41d0b92ef844261715fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f808811471644ee383b2ed37ff75a165",
       "max": 1,
       "style": "IPY_MODEL_ee9b828a9f0044b89d923e2df6927ced",
       "value": 1
      }
     },
     "3a24163b263f4bc7ab02cc9ae40ed2c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3b28fe3f8c6a4769a2b4864e7c9dacf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4c1178bfb7b342e8b972e2869521befb",
        "IPY_MODEL_554f516681934ec1a693e1bcd706156c",
        "IPY_MODEL_6c140b6cae7b4c2d80b8ad9968e1f7fd"
       ],
       "layout": "IPY_MODEL_1b67d92e26f549199c816c82119af34a"
      }
     },
     "3b4374c5ec9e4d77b3b1c6ddb7c71086": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3b5ec45ad8724b7c80c0c68252d050b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3b7a861dcb8147f8ba98aadf78fbc729": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3b8108fd7b634a8788ffcec3d1beb6d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3c5ddd6d59f14dd1868e8a7da74926e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_65b35da130f14302837bed7919dde5c3",
       "style": "IPY_MODEL_98697366d7d14c319140780a9f65d5aa",
       "value": "Overall Progress: 100%"
      }
     },
     "3f2e93615d464c70bd6b357c1ea35c48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3fbaa3b3a41f493c926934afd9f81899": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "424047ca57ee4e66b3d4ffc8abc39790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42ab6708fe7c46b9951fabdf724f615d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42bf3abc843d4790a895d1b45215a576": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "43b23c1de88a4874a6330033ea07c9e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "452a01dcd9d7414f86b3a1e9cb48caf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4a3593c67d6b4c61ab98bdb4033a6f26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_32804186dad9440c88f802d2571b63f4",
       "style": "IPY_MODEL_3b4374c5ec9e4d77b3b1c6ddb7c71086",
       "value": "Joining Batched Feature Maps: 100%"
      }
     },
     "4b8a6aaeb932413989a91d7a98cf6496": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4c1178bfb7b342e8b972e2869521befb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4b8a6aaeb932413989a91d7a98cf6496",
       "style": "IPY_MODEL_de7d15282b5f4649bdd5832863bdc1e8",
       "value": "Overall Progress: 100%"
      }
     },
     "4ca41ecebdd44ddc876724ece757a0f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7e918b9be2c44a2ebeb3cf86740a9773",
       "style": "IPY_MODEL_5c574aa30a9e43349f7405f7fd9ae2a8",
       "value": "Overall Progress: 100%"
      }
     },
     "4caa1dd08d4e494285417bdf2ad2a2a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4a3593c67d6b4c61ab98bdb4033a6f26",
        "IPY_MODEL_7c5205cef28b4709b0af5e984e8e077f",
        "IPY_MODEL_e1fbb499cff148ea96b2077cab9ff770"
       ],
       "layout": "IPY_MODEL_fe8e60445d124214b356406171606b67"
      }
     },
     "4d10121cb42f49ae862a7a873eca9e1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4d36b1b91b5f4fdea5d50a1e668899d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c8ef001776c3489eb7f49bf488ef8afa",
       "max": 1,
       "style": "IPY_MODEL_716b28be52f84fdab4ddb33594b97182",
       "value": 1
      }
     },
     "4d5a180290b8472cb41c6aa1e7ec510d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7f8c840635b34ea69b409b1b9902a098",
       "style": "IPY_MODEL_c269a5e8f57a4ee78284efa5cd7a54a0",
       "value": " 3/3 [00:49&lt;00:00, 15.76s/it]"
      }
     },
     "4e70e8d81bfd47fbaa6d0ae21db4ea11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_647d702e0864442f8c516e738253619e",
        "IPY_MODEL_558c3004c52d4fcaae6fcadbd823f50e",
        "IPY_MODEL_4d5a180290b8472cb41c6aa1e7ec510d"
       ],
       "layout": "IPY_MODEL_43b23c1de88a4874a6330033ea07c9e9"
      }
     },
     "4fa7fb053cfe449d9e789616f2afceae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "51219d39a84042e2880c85a41944ad9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5124589ccc3d4c32a18ed4e790c354ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "53bb4f6851ee43e7a7e0ecd913799275": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5a56782330c541618858b5064e568bff",
       "style": "IPY_MODEL_a1a4ca6bbf1a4201b84f25a7683ef0f8",
       "value": " 3/3 [00:00&lt;00:00, 19.75it/s]"
      }
     },
     "53d6b813eb4849d59cf0c35d79af2a68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "554f516681934ec1a693e1bcd706156c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_33a73e19318242c1b4158fb6de0c31ed",
       "max": 3,
       "style": "IPY_MODEL_5884dc14b0ae4b8baf386ee6afea17f4",
       "value": 3
      }
     },
     "558c3004c52d4fcaae6fcadbd823f50e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e8a1c2af824a46be9ab9b6581ae704bf",
       "max": 3,
       "style": "IPY_MODEL_3fbaa3b3a41f493c926934afd9f81899",
       "value": 3
      }
     },
     "56563cd230f64a98a01eaf93cccf2486": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c14d0b1def3d4cf1ac63478fa167c6f0",
       "style": "IPY_MODEL_7648801a1b0c43f3a921a82b4148a706",
       "value": " 1/1 [00:49&lt;00:00, 49.47s/it]"
      }
     },
     "568c98274344497aaf37733d78adef26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5884dc14b0ae4b8baf386ee6afea17f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5a56782330c541618858b5064e568bff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5adfd3b94d3a4cf89c7d5765d96d7bb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_cb02c4e0c9d7471aaf23a3b2e10a54bd",
       "max": 3,
       "style": "IPY_MODEL_736e646921404570879919cb45da92b6",
       "value": 3
      }
     },
     "5c574aa30a9e43349f7405f7fd9ae2a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5dfc27425ed84c2dbe7ce84107e49219": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5f03f395b22d42c48d99faa8fc94f95b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "60359029867c49caad9cece00c62168a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7e5962d769e94b2793d5e177617f5d18",
       "style": "IPY_MODEL_f17101174277485c8d9ca2a1b8941230",
       "value": "Global Progress: 100%"
      }
     },
     "60c9aaffb00246f38346b67ff331d355": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6142b7a024de429095cecbe795c3925a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6213cfb71fa64e8ca10652ab2cf68114": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6ef2a741dd9443da88189204d47b750f",
       "style": "IPY_MODEL_5f03f395b22d42c48d99faa8fc94f95b",
       "value": " 3/3 [00:00&lt;00:00, 37.96it/s]"
      }
     },
     "6300e834eb834649a16f6c56e699177e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "647d702e0864442f8c516e738253619e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_42bf3abc843d4790a895d1b45215a576",
       "style": "IPY_MODEL_66f96cb139ea42e29a391656edf69864",
       "value": "Overall Progress: 100%"
      }
     },
     "65b35da130f14302837bed7919dde5c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "66167e7d6133466880dd6991e779a2b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "66f96cb139ea42e29a391656edf69864": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "67443b92adbd4c1fb92507d9df324e02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6899fd74da334d12a45b8c2f1b7d8515": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3c5ddd6d59f14dd1868e8a7da74926e9",
        "IPY_MODEL_1f0eb997a63d41c18738c761985db8af",
        "IPY_MODEL_56563cd230f64a98a01eaf93cccf2486"
       ],
       "layout": "IPY_MODEL_81e48941b68e44b4bc2be5082ba984b1"
      }
     },
     "6b2486e791e04afc96ee13b5cd3f3eb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6c140b6cae7b4c2d80b8ad9968e1f7fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e4a44ef7fc194c64bfc4371b77638ea3",
       "style": "IPY_MODEL_6d081cb53c7c40b087489cfeab3e8f2c",
       "value": " 3/3 [00:36&lt;00:00, 11.87s/it]"
      }
     },
     "6cff13a40d0d4499ba375f202b954790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_66167e7d6133466880dd6991e779a2b1",
       "max": 3,
       "style": "IPY_MODEL_d2e743a8aafe453eaf243275951468be",
       "value": 3
      }
     },
     "6d081cb53c7c40b087489cfeab3e8f2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6d53b47679074f2d84568b4a183c7b5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6ef2a741dd9443da88189204d47b750f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "716b28be52f84fdab4ddb33594b97182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7189410ecfad45d3948f9f8649eec39c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4d10121cb42f49ae862a7a873eca9e1e",
       "style": "IPY_MODEL_90b64a4897bd4d169b41a5f7af17a283",
       "value": "Overall Progress: 100%"
      }
     },
     "736e646921404570879919cb45da92b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "73f879fe3f98401c9547805711891d1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2053625813304b0fb20ecd16b9344c55",
        "IPY_MODEL_4d36b1b91b5f4fdea5d50a1e668899d8",
        "IPY_MODEL_cba26ccf4c684af98cbd9e70028f8ca2"
       ],
       "layout": "IPY_MODEL_51219d39a84042e2880c85a41944ad9b"
      }
     },
     "75b79a23b6b142e890407e46e55d6b77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9d8e2efac22b4f9ab279df3e9e61228b",
       "style": "IPY_MODEL_b8e527032cd940bb98b2c9744cb06805",
       "value": " 3/3 [00:00&lt;00:00, 17.64it/s]"
      }
     },
     "7600daff4deb4d53aa6ec5349ca91d99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_352f0ea477e34bd68a525fcf141f1086",
        "IPY_MODEL_5adfd3b94d3a4cf89c7d5765d96d7bb4",
        "IPY_MODEL_fdde736efb2940f8826335f95932aac5"
       ],
       "layout": "IPY_MODEL_da32c63a7f92453fb82086e0f12ad555"
      }
     },
     "7648801a1b0c43f3a921a82b4148a706": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "79319fe7167d4b0abd8defc27036a130": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "798b2aaafb034d6d9d152c43bb92c722": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7b06d52d098e47888ca00da88405443e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7c5205cef28b4709b0af5e984e8e077f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a710bdc068424ef187a7d4b34ecd26ac",
       "max": 3,
       "style": "IPY_MODEL_d29414c0d44f43f1ab8dcf3394d526f5",
       "value": 3
      }
     },
     "7d91f76fe60e4de0924a7fd767484f4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7dcc5538628e4467be225c705c1c594e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e4a08fb0d58d491a959241141933d420",
       "style": "IPY_MODEL_ecc034223c08489d903adfc8cfc0623a",
       "value": "Global Progress: 100%"
      }
     },
     "7e5962d769e94b2793d5e177617f5d18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7e918b9be2c44a2ebeb3cf86740a9773": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7f8c840635b34ea69b409b1b9902a098": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "80278bf58cb449518089a73281d7552e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8126562f23c94a6d8335ae53db567e60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d3a89d6d024348de887316504b617796",
       "style": "IPY_MODEL_e587a19edc904050bcfe923b9687c312",
       "value": " 1/1 [00:01&lt;00:00,  1.97s/it]"
      }
     },
     "81e48941b68e44b4bc2be5082ba984b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "84dd9d72570141b3830cd8fc8646ff5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_30e4b33f169e4dc5ace5e3965f21ee98",
       "max": 3,
       "style": "IPY_MODEL_6300e834eb834649a16f6c56e699177e",
       "value": 3
      }
     },
     "87583ff8ac64413bb8c01ec9bf7194f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "89dcbfbfd22b42c091e250915c7e4c99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8a640a32504e47e2943c2f5acd6d4341": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8aa84a197c2e43a3a61139b15e527075": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b11aadc67604688ad10b920599148ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8d0e63c0edb8433aa0c5baf898713ecb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_210867d9f93e4cb5b4be0f1ab98eade9",
       "max": 3,
       "style": "IPY_MODEL_8b11aadc67604688ad10b920599148ae",
       "value": 3
      }
     },
     "8d9354bde74040fea1616da176a14edc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_798b2aaafb034d6d9d152c43bb92c722",
       "style": "IPY_MODEL_5124589ccc3d4c32a18ed4e790c354ea",
       "value": "Joining Batched Feature Maps: 100%"
      }
     },
     "8ebbbe12136b4c559182346faa4c0f9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8fa6d547eab44415b41e80099355e742": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90b64a4897bd4d169b41a5f7af17a283": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90bf94a856504e13bdd4ca073dfde68c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2a3e800acfcd42199140962eb3475c65",
       "style": "IPY_MODEL_aff730ca1d6441198aa3a901d8fad98f",
       "value": " 3/3 [00:00&lt;00:00, 52.10it/s]"
      }
     },
     "910dab153cba484eb3e2524d01a397ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "96602110095946d6a41f88a77eb46a27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "98697366d7d14c319140780a9f65d5aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "995fcc7884fc479fb2d31d444ac73968": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "99c20e656c2547138bc149b3692e293f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9d0ffaeb6d8e4348b09bba4b34d65fe3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9d8e2efac22b4f9ab279df3e9e61228b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a1a4ca6bbf1a4201b84f25a7683ef0f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a2eddc5f32e64e78ab42fb18bb848fb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e8292d099d11479ea30ba89abf4a0214",
        "IPY_MODEL_84dd9d72570141b3830cd8fc8646ff5a",
        "IPY_MODEL_6213cfb71fa64e8ca10652ab2cf68114"
       ],
       "layout": "IPY_MODEL_235d69ffff014c999f79525a7516f3c3"
      }
     },
     "a710bdc068424ef187a7d4b34ecd26ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a84b770212984f8fb7b3eed12205b996": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7189410ecfad45d3948f9f8649eec39c",
        "IPY_MODEL_8d0e63c0edb8433aa0c5baf898713ecb",
        "IPY_MODEL_d9c02d1138f8422b867fed84df796e4c"
       ],
       "layout": "IPY_MODEL_29fd666305c340ff92e3ecc54d92e7e6"
      }
     },
     "accf6b4ea30d4504bc60d7d44252688e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "aff730ca1d6441198aa3a901d8fad98f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b2a3ffdc8d9041c38c24214366ce00c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6142b7a024de429095cecbe795c3925a",
       "style": "IPY_MODEL_cc773a122275497c8a5d162a35903ecc",
       "value": " 3/3 [00:00&lt;00:00,  4.13it/s]"
      }
     },
     "b2ceeaa581534e2d8dd72c8f06525e63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b8e527032cd940bb98b2c9744cb06805": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ba56b2fb8c754772ace005e2ad52fab1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c1c4df98a8bf41afb173430e83d8a165",
        "IPY_MODEL_2bac393dd90f4656834cd50e2316d0a5",
        "IPY_MODEL_90bf94a856504e13bdd4ca073dfde68c"
       ],
       "layout": "IPY_MODEL_3b5ec45ad8724b7c80c0c68252d050b1"
      }
     },
     "ba621feed50f4699a4587b41532964d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_353edd792cca4bc59b24cc9090ce929b",
        "IPY_MODEL_e4dae2f07a9c4dbea7ab1a6afa1d5e9e",
        "IPY_MODEL_75b79a23b6b142e890407e46e55d6b77"
       ],
       "layout": "IPY_MODEL_f4c74cbd2e3b47b28ca77d68673baad5"
      }
     },
     "c14d0b1def3d4cf1ac63478fa167c6f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c1c4df98a8bf41afb173430e83d8a165": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_030d3326eaa342c792a97b0b792cdaf5",
       "style": "IPY_MODEL_87583ff8ac64413bb8c01ec9bf7194f4",
       "value": "Joining Batched Feature Maps: 100%"
      }
     },
     "c269a5e8f57a4ee78284efa5cd7a54a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c5edf3cf4d0d49ef93a8270fee6cd09b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d3db11c6605b4ba49b945714679cbe40",
       "style": "IPY_MODEL_e2dfc6411cdb4c51b724868cfe9957f1",
       "value": "Joining Batched Feature Maps: 100%"
      }
     },
     "c8ef001776c3489eb7f49bf488ef8afa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cb02c4e0c9d7471aaf23a3b2e10a54bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cba26ccf4c684af98cbd9e70028f8ca2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fbb941434d5e4fb8a63afe60385744b5",
       "style": "IPY_MODEL_60c9aaffb00246f38346b67ff331d355",
       "value": " 1/1 [00:59&lt;00:00, 59.71s/it]"
      }
     },
     "cc773a122275497c8a5d162a35903ecc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cd71af7cde3d47b8a0b3c3e4c6140178": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d29414c0d44f43f1ab8dcf3394d526f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d2e743a8aafe453eaf243275951468be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d36de359745f4525b201c8889843cc13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d3a89d6d024348de887316504b617796": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d3db11c6605b4ba49b945714679cbe40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d4f2dc63ade74964ba4d05f51c34b39e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d59510a52ce44f2fbfc305ad70f4ae63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_dc43a25b8bd44908821ad55980a30090",
        "IPY_MODEL_6cff13a40d0d4499ba375f202b954790",
        "IPY_MODEL_26b2e5eced6544509450d6bbc649dbf3"
       ],
       "layout": "IPY_MODEL_6d53b47679074f2d84568b4a183c7b5c"
      }
     },
     "d6b8e901d6c04e008e5ec9e7e697a1d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_1de317b0b8084e22a1c1bd594ee734e3",
       "max": 3,
       "style": "IPY_MODEL_f48a4dc1e3a34016b5fa5a63773a3c94",
       "value": 3
      }
     },
     "d92626fcb26d4ab2bb3625f9d038697f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3f2e93615d464c70bd6b357c1ea35c48",
       "max": 1,
       "style": "IPY_MODEL_99c20e656c2547138bc149b3692e293f",
       "value": 1
      }
     },
     "d9c02d1138f8422b867fed84df796e4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_01e154d8de2d47c4868d854a3cf9e781",
       "style": "IPY_MODEL_424047ca57ee4e66b3d4ffc8abc39790",
       "value": " 3/3 [00:41&lt;00:00, 13.61s/it]"
      }
     },
     "da32c63a7f92453fb82086e0f12ad555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dc43a25b8bd44908821ad55980a30090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9d0ffaeb6d8e4348b09bba4b34d65fe3",
       "style": "IPY_MODEL_df7f2e1357a74b9fb1a2e38eefe9df1a",
       "value": "Feature Extraction (DataLoader): 100%"
      }
     },
     "dca0db5c05b541aea120d1445beef2a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dcd785b4e76e4b9c943faaad5a86beaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ddbbbdb21cb04012825ffae89fbdbba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "de7d15282b5f4649bdd5832863bdc1e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "df7f2e1357a74b9fb1a2e38eefe9df1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e1695bd0d90f488d8613f4d1d32a05c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8d9354bde74040fea1616da176a14edc",
        "IPY_MODEL_170fad9d3d8c48d68d93d902cc4b31e1",
        "IPY_MODEL_53bb4f6851ee43e7a7e0ecd913799275"
       ],
       "layout": "IPY_MODEL_b2ceeaa581534e2d8dd72c8f06525e63"
      }
     },
     "e1fbb499cff148ea96b2077cab9ff770": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4fa7fb053cfe449d9e789616f2afceae",
       "style": "IPY_MODEL_6b2486e791e04afc96ee13b5cd3f3eb1",
       "value": " 3/3 [00:00&lt;00:00,  3.86it/s]"
      }
     },
     "e2dfc6411cdb4c51b724868cfe9957f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e4a08fb0d58d491a959241141933d420": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4a44ef7fc194c64bfc4371b77638ea3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4dae2f07a9c4dbea7ab1a6afa1d5e9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_79319fe7167d4b0abd8defc27036a130",
       "max": 3,
       "style": "IPY_MODEL_accf6b4ea30d4504bc60d7d44252688e",
       "value": 3
      }
     },
     "e587a19edc904050bcfe923b9687c312": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e6bfb7553d704c2796cdd9066da4cbf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c5edf3cf4d0d49ef93a8270fee6cd09b",
        "IPY_MODEL_ea44a1849a1146b79de16c4d7048a6c7",
        "IPY_MODEL_b2a3ffdc8d9041c38c24214366ce00c7"
       ],
       "layout": "IPY_MODEL_568c98274344497aaf37733d78adef26"
      }
     },
     "e8292d099d11479ea30ba89abf4a0214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cd71af7cde3d47b8a0b3c3e4c6140178",
       "style": "IPY_MODEL_dcd785b4e76e4b9c943faaad5a86beaa",
       "value": "Joining Batched Feature Maps: 100%"
      }
     },
     "e8a1c2af824a46be9ab9b6581ae704bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ea080d698a5c426ab327cd68c7c68daa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2859c9c4151a4d15840a975080aa4819",
       "style": "IPY_MODEL_995fcc7884fc479fb2d31d444ac73968",
       "value": " 3/3 [00:38&lt;00:00, 12.29s/it]"
      }
     },
     "ea44a1849a1146b79de16c4d7048a6c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3b8108fd7b634a8788ffcec3d1beb6d4",
       "max": 3,
       "style": "IPY_MODEL_dca0db5c05b541aea120d1445beef2a1",
       "value": 3
      }
     },
     "ea61c5dd95b84df9be069c16fa0dc73b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4ca41ecebdd44ddc876724ece757a0f3",
        "IPY_MODEL_d6b8e901d6c04e008e5ec9e7e697a1d3",
        "IPY_MODEL_ea080d698a5c426ab327cd68c7c68daa"
       ],
       "layout": "IPY_MODEL_d36de359745f4525b201c8889843cc13"
      }
     },
     "ecc034223c08489d903adfc8cfc0623a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ee9b828a9f0044b89d923e2df6927ced": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f17101174277485c8d9ca2a1b8941230": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f41738459f2945129c19d3f51ad2547e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f48a4dc1e3a34016b5fa5a63773a3c94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f4c74cbd2e3b47b28ca77d68673baad5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f6a30bc60d554f0aae74aab64ef6bf25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f808811471644ee383b2ed37ff75a165": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f86c4cdfad0d47a6b106c70ef72b9920": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_60359029867c49caad9cece00c62168a",
        "IPY_MODEL_d92626fcb26d4ab2bb3625f9d038697f",
        "IPY_MODEL_8126562f23c94a6d8335ae53db567e60"
       ],
       "layout": "IPY_MODEL_d4f2dc63ade74964ba4d05f51c34b39e"
      }
     },
     "fa1879106eae41c493c3a501d2f9e138": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3a24163b263f4bc7ab02cc9ae40ed2c5",
       "max": 3,
       "style": "IPY_MODEL_53d6b813eb4849d59cf0c35d79af2a68",
       "value": 3
      }
     },
     "fbb941434d5e4fb8a63afe60385744b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fdde736efb2940f8826335f95932aac5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_89dcbfbfd22b42c091e250915c7e4c99",
       "style": "IPY_MODEL_8fa6d547eab44415b41e80099355e742",
       "value": " 3/3 [00:00&lt;00:00, 29.23it/s]"
      }
     },
     "fe8e60445d124214b356406171606b67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
