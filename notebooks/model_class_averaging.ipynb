{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936dac24-ad68-414a-9760-fae96194d4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch4/lisik3/emcmaho7/SIfMRI_modeling/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.stats import calculate_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a02395-bbed-4cd1-afc9-4a19afdf3d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 files found\n"
     ]
    }
   ],
   "source": [
    "class ModelAveraging:\n",
    "    def __init__(self, args):\n",
    "        self.process = 'ModelAveraging'\n",
    "        self.model_class = 'VisionNeuralEncoding'\n",
    "        self.model_subpath = 'grouped_average'\n",
    "        self.voxel_id = 9539 #test voxel in EVC\n",
    "        self.top_dir = f'/home/emcmaho7/scratch4-lisik3/emcmaho7/SIfMRI_modeling/data/interim'\n",
    "\n",
    "        self.ut_path = f'{top_dir}/{self.process}'\n",
    "        Path(out_path).mkdir(exist_ok=True, parents=True)\n",
    "        cols2keep = ['voxel_id', 'layer_relative_depth',\n",
    "                    'train_score', 'test_score',\n",
    "                    'r_null_dist', 'r_var_dist']\n",
    "\n",
    "    def run(self): \n",
    "        if self.model_subpath is not None: \n",
    "            file_path = f'{self.top_dir}/{self.model_class}/{self.model_subpath}/'\n",
    "        else: \n",
    "            file_path = f'{self.top_dir}/{self.model_class}'\n",
    "    \n",
    "        files = glob(f'{file_path}/*.pkl.gz')\n",
    "        n_files = len(files)\n",
    "        print(f'{len(files)} files found')\n",
    "\n",
    "        df, n_files = load_files(files)\n",
    "        print(df.loc[df.voxel_id == voxel_id])\n",
    "\n",
    "        df = divide_pd_array(df, n_files)\n",
    "        print(df.loc[df.voxel_id == voxel_id])\n",
    "\n",
    "        # calculate the confidence interval\n",
    "        df[['lower_ci', 'upper_ci']] = df['r_var_dist'].apply(lambda arr: pd.Series(compute_confidence_intervals(arr)))\n",
    "        print(df.loc[df.voxel_id == voxel_id])\n",
    "\n",
    "        # calculate the p value\n",
    "        df['p'] = df.apply(calculate_p_df, axis=1)\n",
    "        print(df.loc[df.voxel_id == voxel_id])\n",
    "\n",
    "        save_start = time.time()\n",
    "        df.to_pickle(f'{out_path}/{model_class}_{model_subpath}.pkl.gz')\n",
    "        save_time = time.time() - save_start\n",
    "        elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(save_time))\n",
    "        print(f'Saved in {elapsed}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997937a2-2d4e-4bca-b515-b2f8b219633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_arrays(series):\n",
    "    # Stack arrays vertically and compute sum along the first axis (rows)\n",
    "    return np.nansum(np.vstack(series), axis=0)\n",
    "\n",
    "def compute_confidence_intervals(arr):\n",
    "    lower = np.nanpercentile(arr, 2.5)\n",
    "    upper = np.nanpercentile(arr, 97.5)\n",
    "    return lower, upper\n",
    "\n",
    "def calculate_p_df(row):\n",
    "    r_value = row['test_score']  # The 'r' value for the current row\n",
    "    r_null_array = row['r_null_dist']  # The 'r_null' array for the current row\n",
    "    return calculate_p(r_null_array, r_value, n_perm_=len(r_null_array), H0_='greater')\n",
    "\n",
    "def load_files(files):\n",
    "    # Load the files and sum them up \n",
    "    df = None\n",
    "    n_final_files = 0\n",
    "    for file in tqdm(files, total=n_files, desc='Loading files'): \n",
    "        try: \n",
    "            pkl = pd.read_pickle(file)[cols2keep]\n",
    "\n",
    "            # remove voxels not in roi\n",
    "            if 'roi_name' in pkl.columns: \n",
    "                pkl = pkl.loc[pkl.roi_name != 'none'].reset_index()\n",
    "\n",
    "            if df is None: \n",
    "                df = pkl\n",
    "            else:\n",
    "                #After the first file has been loaded, concatenate the data and add it together\n",
    "                df = pd.concat([df, pkl])\n",
    "                df = df.groupby('voxel_id').agg({\n",
    "                                                'train_score': 'sum',\n",
    "                                                'test_score': 'sum',\n",
    "                                                'layer_relative_depth': 'sum',\n",
    "                                                'r_null_dist': sum_of_arrays,\n",
    "                                                'r_var_dist': sum_of_arrays\n",
    "                                                }).reset_index()\n",
    "            n_final_files += 1\n",
    "        except:\n",
    "            print(f'could not load {file}')\n",
    "    return df \n",
    "\n",
    "def divide_pd_array(df, n): \n",
    "    def divide_array(arr):\n",
    "        return arr / n\n",
    "\n",
    "    # Get the mean by averaging by the total number of models\n",
    "    columns_to_divide = ['train_score', 'test_score', 'layer_relative_depth', 'r_null_dist', 'r_var_dist']\n",
    "    for col in columns_to_divide:\n",
    "        if isinstance(df[col][0], np.ndarray):\n",
    "            # Apply division to arrays\n",
    "            df[col] = df[col].apply(divide_array)\n",
    "        else:\n",
    "            # Apply division to numeric columns\n",
    "            df[col] = df[col] / n\n",
    "    print(df.loc[df.voxel_id == voxel_id])\n",
    "    return df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepjuice",
   "language": "python",
   "name": "deepjuice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
